{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1372,
     "status": "ok",
     "timestamp": 1592661084440,
     "user": {
      "displayName": "Helder Daniel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9_X9PHXyfxsFqdQBJarSFy5TpLITVEg043ihVUA=s64",
      "userId": "03611350071843918342"
     },
     "user_tz": -60
    },
    "id": "1WnJ6t04g90a"
   },
   "outputs": [],
   "source": [
    "#Run in Colab\n",
    "useColab = True\n",
    "\n",
    "#Init notebook and get data?\n",
    "initNotebook = True\n",
    "\n",
    "seed=6512\n",
    "import numpy as np\n",
    "np.random.seed(seed) # for reproducibility\n",
    "import random\n",
    "random.seed(seed)\n",
    "\n",
    "import statistics\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1881,
     "status": "ok",
     "timestamp": 1592661084966,
     "user": {
      "displayName": "Helder Daniel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9_X9PHXyfxsFqdQBJarSFy5TpLITVEg043ihVUA=s64",
      "userId": "03611350071843918342"
     },
     "user_tz": -60
    },
    "id": "P08pSR2Ngbbz"
   },
   "outputs": [],
   "source": [
    "#Define hardware to use\n",
    "#Set float 16,32 or 64 on supported GPUs\n",
    "#https://www.kaggle.com/danmoller/keras-training-with-float16-test-kernel-2\n",
    "DTYPE  = None       #defaults to float32\n",
    "#DTYPE = 'float16'\n",
    "#DTYPE = 'float32'\n",
    "#DTYPE = 'float64'\n",
    "\n",
    "#Use TPU\n",
    "useTPU = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 199
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5459,
     "status": "ok",
     "timestamp": 1592661088554,
     "user": {
      "displayName": "Helder Daniel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9_X9PHXyfxsFqdQBJarSFy5TpLITVEg043ihVUA=s64",
      "userId": "03611350071843918342"
     },
     "user_tz": -60
    },
    "id": "h5vXItUxyM3Z",
    "outputId": "c0638f8a-37f3-4276-ecd2-943f0b7bb830"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hdf5storage in /usr/local/lib/python3.6/dist-packages (0.1.15)\n",
      "Requirement already satisfied: numpy; python_version >= \"3.4\" in /usr/local/lib/python3.6/dist-packages (from hdf5storage) (1.18.5)\n",
      "Requirement already satisfied: h5py>=2.1; python_version >= \"3.3\" in /usr/local/lib/python3.6/dist-packages (from hdf5storage) (2.10.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py>=2.1; python_version >= \"3.3\"->hdf5storage) (1.12.0)\n",
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
      "aux 1.15.34\n",
      "model 1.15.34\n",
      "common 1.5.1\n",
      "TF version:  2.2.0\n"
     ]
    }
   ],
   "source": [
    "#Init Local or Colab New\n",
    "if initNotebook:\n",
    "  if useColab:\n",
    "    !pip3 install hdf5storage\n",
    "\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "\n",
    "    #import sys\n",
    "    #sys.path.append('gdrive/My Drive/Colab Notebooks/classifier/lib')\n",
    "    ##!cp gdrive/My\\ Drive/Colab\\ Notebooks/classifier/* .\n",
    "    ##!python3 classifier-v10.py\n",
    "\n",
    "if useColab:\n",
    "  %run gdrive/My\\ Drive/Colab\\ Notebooks/lib/auxf.ipynb $useColab\n",
    "  %run gdrive/My\\ Drive/Colab\\ Notebooks/lib/common.ipynb\n",
    "else:\n",
    "  %run lib/common.ipynb\n",
    "  %run lib/auxf.ipynb $useColab\n",
    "  \n",
    "print(\"TF version: \",tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11022,
     "status": "ok",
     "timestamp": 1592661094129,
     "user": {
      "displayName": "Helder Daniel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9_X9PHXyfxsFqdQBJarSFy5TpLITVEg043ihVUA=s64",
      "userId": "03611350071843918342"
     },
     "user_tz": -60
    },
    "id": "19g6Yn2PBkPR",
    "outputId": "4ca69ddc-73ea-4c3e-8fae-d3d21d6edf16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2019 NVIDIA Corporation\n",
      "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
      "Cuda compilation tools, release 10.1, V10.1.243\n",
      "Sat Jun 20 13:51:31 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   40C    P8     7W /  75W |      0MiB /  7611MiB |      0%      Default |\n",
      "|                               |                      |                 ERR! |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Install cuda 9.0\n",
    "#BY Default is installed 10.0\n",
    "#https://stackoverflow.com/questions/51888118/how-to-downgrade-tensorflow-version-in-colab\n",
    "#\n",
    "'''\n",
    "!wget https://developer.nvidia.com/compute/cuda/9.0/Prod/local_installers/cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64-deb\n",
    "!dpkg -i cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64-deb\n",
    "!apt-key add /var/cuda-repo-9-0-local/7fa2af80.pub\n",
    "!apt-get update\n",
    "!apt-get install cuda=9.0.176-1\n",
    "'''\n",
    "!nvcc --version\n",
    "if useTPU == False:\n",
    "  !nvidia-smi\n",
    "os.system('uname -a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11010,
     "status": "ok",
     "timestamp": 1592661094130,
     "user": {
      "displayName": "Helder Daniel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9_X9PHXyfxsFqdQBJarSFy5TpLITVEg043ihVUA=s64",
      "userId": "03611350071843918342"
     },
     "user_tz": -60
    },
    "id": "oWmY7LlxoNSD"
   },
   "outputs": [],
   "source": [
    "#by Default on June, 27th 2019, TF==1.14.0rc1 GPU version\n",
    "#IF installing tensorflow==1.14.0, JUST INSTALLs CPU SLOWER VERSION\n",
    "#https://stackoverflow.com/questions/51888118/how-to-downgrade-tensorflow-version-in-colab\n",
    "#\n",
    "if useTPU:\n",
    "  #Use pip3 install tensorflow-gpu==x.xx.x\n",
    "  #!pip3 install tensorflow-gpu==1.12.0  #(1.67/15.6 secs) (NEEDS cuda 9.x)\n",
    "  #!pip3 install tensorflow-gpu==1.13.1  #(1.67/15.6 secs) on T4 (0.1/full dataset) Faster on TPU!!!\n",
    "  #!pip3 install tensorflow-gpu==1.14.0  #(2.71/17.7 secs)\n",
    "  #!pip3 install tensorflow-gpu==1.14.0rc1  #(1.55/12.5 secs) (Default, on 27th june )\n",
    "  #!pip3 install tensorflow-gpu==2.0.0b1 #(2.71/15.6 secs) #Fails detect TPU\n",
    "  import tensorflow as tf\n",
    "  print(tf.__version__)\n",
    "  tfVersion114=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11003,
     "status": "ok",
     "timestamp": 1592661094131,
     "user": {
      "displayName": "Helder Daniel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9_X9PHXyfxsFqdQBJarSFy5TpLITVEg043ihVUA=s64",
      "userId": "03611350071843918342"
     },
     "user_tz": -60
    },
    "id": "E0FwUP5Rgbbv"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10996,
     "status": "ok",
     "timestamp": 1592661094131,
     "user": {
      "displayName": "Helder Daniel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9_X9PHXyfxsFqdQBJarSFy5TpLITVEg043ihVUA=s64",
      "userId": "03611350071843918342"
     },
     "user_tz": -60
    },
    "id": "HlNvXXzq7hl3"
   },
   "outputs": [],
   "source": [
    "#If True use CNN else MLP (dense)\n",
    "useCNN = '1D' # '2D' or None for dense MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10988,
     "status": "ok",
     "timestamp": 1592661094132,
     "user": {
      "displayName": "Helder Daniel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9_X9PHXyfxsFqdQBJarSFy5TpLITVEg043ihVUA=s64",
      "userId": "03611350071843918342"
     },
     "user_tz": -60
    },
    "id": "5R-62mz4gbb5"
   },
   "outputs": [],
   "source": [
    "#Signal config\n",
    "#timeSegmentLength = 50000\n",
    "#timeSegmentLength = 787   #for features file\n",
    "#timeSegmentLength = 3072\n",
    "#timeSegmentLength = 6144\n",
    "timeSegmentLength = 6000\n",
    "samplesSlice \t  = 1    #get smaller test set\n",
    "samplesPart  \t  = 0    #part to use (part > 0 works only with samplesSlice==2 for now)\n",
    "windowSlice     = 1    #set smaller windows\n",
    "numClasses      = 7    #Fault classes\n",
    "oneHotEncode    = False\n",
    "\n",
    "#reduce input by this factor getting only multiple elements of signal\n",
    "#if underSample is 2 gets only the even elemnts of the 50000 points signal\n",
    "#if underSample is 10 gets only the 1/10 elements, spaced by 10, of the 50000 points signal\n",
    "#we can think of this as a step in a for\n",
    "underSample = 1\n",
    "inputLen : int = int(timeSegmentLength / underSample) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10983,
     "status": "ok",
     "timestamp": 1592661094133,
     "user": {
      "displayName": "Helder Daniel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9_X9PHXyfxsFqdQBJarSFy5TpLITVEg043ihVUA=s64",
      "userId": "03611350071843918342"
     },
     "user_tz": -60
    },
    "id": "H9O4ccL_gbb8"
   },
   "outputs": [],
   "source": [
    "# Model definition\n",
    "if useCNN == '2D':\n",
    "    conv2Drows   = 3       #no. of channels (update to 8)\n",
    "    conv2Dcols   = 1       #If > 1 stack channel data slices\n",
    "\n",
    "# '1D' or dense MLP\n",
    "else:\n",
    "    conv2Drows   = 1       #No 2nd dim in CNN\n",
    "    conv2Dcols   = 1       #If > 1 stack channels, or stack channel data slices if only one channel\n",
    "    \n",
    "filters          = 32\n",
    "dropOutRatio     = 0.5     #dropout ratio for dropout layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10975,
     "status": "ok",
     "timestamp": 1592661094134,
     "user": {
      "displayName": "Helder Daniel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9_X9PHXyfxsFqdQBJarSFy5TpLITVEg043ihVUA=s64",
      "userId": "03611350071843918342"
     },
     "user_tz": -60
    },
    "id": "Ia1BwxRjgbb_"
   },
   "outputs": [],
   "source": [
    "#Train parameters\n",
    "train = True\n",
    "shuffleValData = False\n",
    "epochs =  100\n",
    "batchSize = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10968,
     "status": "ok",
     "timestamp": 1592661094134,
     "user": {
      "displayName": "Helder Daniel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9_X9PHXyfxsFqdQBJarSFy5TpLITVEg043ihVUA=s64",
      "userId": "03611350071843918342"
     },
     "user_tz": -60
    },
    "id": "WBaudPypgbcD"
   },
   "outputs": [],
   "source": [
    "#Adaptive LR and early stop\n",
    "decayLearningRate    = False\n",
    "bouncingLearningRate = False\n",
    "adaptLearningRate    = False\n",
    "earlyStopStall       = False\n",
    "metricES             = 'val_loss'\n",
    "metricLR             = 'val_loss'  #metric to chg LR and earlyStop\n",
    "earlyStopACC         = False\n",
    "earlyStopACCmin      = 0.995 #0.995\n",
    "initialLR            = 0.001  #None gives optimizer default: SGD dflt LR = 0.01, Adam = 0.001\n",
    "minLR                = 1e-6\n",
    "reduceLRFactor       = 0.5\n",
    "esPatienceEpochs     = 5\n",
    "alrPatienceEpochs    = 20\n",
    "waitMonitorEpochs    = 0       #wait epoch before start monitoring measure\n",
    "minDeltaStop         = 0.00001  #var to stop after esPatienceStop epochs\n",
    "minDeltaLR           = 0.00001  #var to change LR after alrPatienceStop epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10962,
     "status": "ok",
     "timestamp": 1592661094135,
     "user": {
      "displayName": "Helder Daniel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9_X9PHXyfxsFqdQBJarSFy5TpLITVEg043ihVUA=s64",
      "userId": "03611350071843918342"
     },
     "user_tz": -60
    },
    "id": "pS2eHJwz_QxH"
   },
   "outputs": [],
   "source": [
    "#optimizer setup\n",
    "optimizer = tf.keras.optimizers.Adam(lr=initialLR)\n",
    "#optimizer=tf.keras.optimizers.RMSprop(lr=initialLR) # loss='categorical_crossentropy', metrics=['acc', 'mae', 'mse'])\n",
    "#optimizer=tf.keras.optimizers.Adagrad(lr=initialLR) # loss='categorical_crossentropy', metrics=['acc', 'mae', 'mse'])\n",
    "#optimizer=tf.keras.optimizers.SGD(lr=initialLR)     # loss='mse', metrics=['acc', 'mae', 'mse'])\n",
    "loss='mse'\n",
    "metrics=['acc', 'mae', 'mse'] \n",
    "#loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "#metrics=['sparse_categorical_accuracy']\n",
    "#loss=tf.keras.losses.categorical_crossentropy,\n",
    "#metrics=['categorical_accuracy'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11433,
     "status": "ok",
     "timestamp": 1592661094613,
     "user": {
      "displayName": "Helder Daniel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9_X9PHXyfxsFqdQBJarSFy5TpLITVEg043ihVUA=s64",
      "userId": "03611350071843918342"
     },
     "user_tz": -60
    },
    "id": "1hgW_bgbgbcG"
   },
   "outputs": [],
   "source": [
    "#I/O setup\n",
    "loadModel   = False\n",
    "saveModel   = True\n",
    "forceCompileModel = True\n",
    "saveEpochs = 1 #save at how many epochs\n",
    "\n",
    "if useColab:\n",
    "    recordpath='gdrive/My Drive/Colab Notebooks/00data/record/'\n",
    "    exppath='gdrive/My Drive/Colab Notebooks/00data/record/experiments/'\n",
    "    storagepath='gdrive/My Drive/Colab Notebooks/00data/storage/'\n",
    "else:\n",
    "    recordpath='/home/hdaniel/Downloads/record/'\n",
    "    exppath='/home/hdaniel/Downloads/record/experiments/'\n",
    "    storagepath='/home/hdaniel/Downloads/'\n",
    "\n",
    "#loadModelFN     = recordpath + 'model-u1-e100-50000-10-estrides5.h5'\n",
    "#loadModelFN     = recordpath + 'model-u1-e100-25000-10-estrides5.h5'\n",
    "#loadModelFN     = recordpath + 'model-u1-e200-25000-10-estrides5-SGD0.001.h5'\n",
    "#loadModelFN     = recordpath + 'modelBest-200+45.h5'\n",
    "#loadModelFN     = recordpath + 'modelBest-2-100-100.h5'\n",
    "#loadModelFN     = recordpath + 'modelBest-2-600.h5'\n",
    "#loadModelFN     = recordpath + 'modelBest.h5'\n",
    "#loadModelFN     = recordpath + 'cnnctbu/cnn32-3072-modelBest-1300.h5'\n",
    "loadModelFN     = recordpath + 'cnnctbu/00-cnn32-no-500.h5'\n",
    "loadModelFN     = recordpath + 'cnnctbu/00-cnn31-309e-LR0.0005-2000pts-acc100loss0.h5'\n",
    "saveBestModelFN = recordpath + 'modelBest.h5'\n",
    "#saveBestModelFN = recordpath + 'bouncing/{epoch:04d}-{l5:08d}-{val_loss:.5f}-{val_acc:.5f}-' + 'modelBest.h5'\n",
    "saveLastModelFN = recordpath + 'modelLast.h5'\n",
    "#dataFN          = storagepath + 'raw_50000_003_dataset_Quantile_4_classes.mat'  #4 classes\n",
    "#dataFN          = storagepath + 'raw_50000_003_qnorm_even.mat'  #36 classes\n",
    "#dataFN          = storagepath + 'datactbu.mat' #unshuffled\n",
    "#dataFN          = storagepath + 'datactbuset.mat'#shuffled\n",
    "#dataFN          = storagepath + 'dataualg.mat'\n",
    "#dataFN          = storagepath + 'raw_3channels-new.mat'\n",
    "#dataFN          = storagepath + 'raw_3channels-s1000.mat'\n",
    "dataFN          = storagepath + 'raw_3channels-w2000-r01.mat'\n",
    "#dataFN          = storagepath + 'features_TS_50000_Ch_003_TR_90_TST_10_dataset_Quantile_4_classes.mat'\n",
    "\n",
    "logFN           = exppath + 'experiment.log'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9CdlbBS4gbcX"
   },
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11426,
     "status": "ok",
     "timestamp": 1592661094615,
     "user": {
      "displayName": "Helder Daniel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9_X9PHXyfxsFqdQBJarSFy5TpLITVEg043ihVUA=s64",
      "userId": "03611350071843918342"
     },
     "user_tz": -60
    },
    "id": "VGOCl8Og6_a_"
   },
   "outputs": [],
   "source": [
    "#%run aux.ipynb $useColab\n",
    "#%run gdrive/My\\ Drive/Colab\\ Notebooks/classifier/aux.ipynb $useColab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12661,
     "status": "ok",
     "timestamp": 1592661095857,
     "user": {
      "displayName": "Helder Daniel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9_X9PHXyfxsFqdQBJarSFy5TpLITVEg043ihVUA=s64",
      "userId": "03611350071843918342"
     },
     "user_tz": -60
    },
    "id": "vRsYqoU8zXet",
    "outputId": "94dd759e-10c3-410a-aecb-ee3f37bc06d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gdrive/My Drive/Colab Notebooks/00data/storage/raw_3channels-w2000-r01.mat\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('X', (7000, 6000), 'single'), ('Y', (7000, 7), 'uint8')]"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np, scipy.io\n",
    "print(dataFN)\n",
    "scipy.io.whosmat(dataFN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 251
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13537,
     "status": "ok",
     "timestamp": 1592661096745,
     "user": {
      "displayName": "Helder Daniel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9_X9PHXyfxsFqdQBJarSFy5TpLITVEg043ihVUA=s64",
      "userId": "03611350071843918342"
     },
     "user_tz": -60
    },
    "id": "MDfQABFZrp8r",
    "outputId": "cd88fe94-9cb3-4aaf-f12a-5d96d18389ad",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data ...\n",
      "done.\n",
      "Preparing data ...\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "done\n",
      "Setting up data ...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "def initData(data):\n",
    "    print('Preparing data ...') \n",
    "    #For quantile dataset or shuffled sets \n",
    "    #trainXs, trainYs, testXs, testYs = getData1(data, underSample)\n",
    "    #For raw dataset (36 classes)\n",
    "    #needs too much memory better do it offline\n",
    "    #trainXs, trainYs, testXs, testYs = getData2(data, 36, 0.9, underSample, 'features', 'labels')\n",
    "    #For CTBU unshuffled dataset\n",
    "    trainXs, trainYs, testXs, testYs = getData2(data, numClasses, 0.8, underSample)\n",
    "    print('done')\n",
    "\n",
    "    #From 36 to 4 classes\n",
    "    if numClasses == 4:\n",
    "        to4classesSet = [(0, 0), (1, 7), (8, 14), (15, 35)]\n",
    "        trainYs = joinClasses(trainYs, to4classesSet)\n",
    "        testYs  = joinClasses(testYs,  to4classesSet)\n",
    "\n",
    "    print('Setting up data ...')\n",
    "    trainXs, trainYs, testXs, testYs = setupData(\n",
    "          trainXs, trainYs, testXs, testYs, \n",
    "          numClasses, samplesSlice, samplesPart, windowSlice, \n",
    "          conv2Drows, conv2Dcols, underSample, useCNN, DTYPE)\n",
    "    print('done')  \n",
    "\n",
    "    if oneHotEncode:\n",
    "        #Transform in one:hot encoding\n",
    "        #Must use in the optimizer tf.keras.losses.categorical_crossentropy\n",
    "        #rather than: tf.keras.losses.sparse_categorical_crossentropy\n",
    "        #If using sparse one_hot is handled by the optimizer must supply not one_hot encoded\n",
    "        trainYs = one_hot(trainYs, numClasses) \n",
    "        testYs  = one_hot(testYs,  numClasses) \n",
    "  \n",
    "    return trainXs, trainYs, testXs, testYs\n",
    "  \n",
    "#Setup data\n",
    "if initNotebook:\n",
    "    print('Loading data ...')\n",
    "    data = loadData(dataFN)\n",
    "    print('done.')        \n",
    "trainXs, trainYs, testXs, testYs = initData(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13530,
     "status": "ok",
     "timestamp": 1592661096749,
     "user": {
      "displayName": "Helder Daniel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9_X9PHXyfxsFqdQBJarSFy5TpLITVEg043ihVUA=s64",
      "userId": "03611350071843918342"
     },
     "user_tz": -60
    },
    "id": "fPuJ7qs3_Fg3",
    "outputId": "743b8e6b-c558-4347-b408-1e047a500277"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 1 0]\n",
      " [0 0 0 0 1 0 0]\n",
      " [0 0 0 1 0 0 0]\n",
      " [0 0 1 0 0 0 0]\n",
      " [0 1 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0]]\n",
      "[[0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 1 0]\n",
      " [0 0 0 0 1 0 0]\n",
      " [0 0 0 1 0 0 0]\n",
      " [0 0 1 0 0 0 0]\n",
      " [0 1 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0]]\n",
      "[800 800 800 800 800 800 800]\n",
      "[200 200 200 200 200 200 200]\n"
     ]
    }
   ],
   "source": [
    "#Print number of samples by classes\n",
    "#Unique classes\n",
    "print(np.unique(trainYs, return_counts=True, axis=0)[0])\n",
    "print(np.unique(testYs, return_counts=True, axis=0)[0])\n",
    "#Number of samples of each unique class\n",
    "print(np.unique(trainYs, return_counts=True, axis=0)[1])\n",
    "print(np.unique(testYs, return_counts=True, axis=0)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14047,
     "status": "ok",
     "timestamp": 1592661097278,
     "user": {
      "displayName": "Helder Daniel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9_X9PHXyfxsFqdQBJarSFy5TpLITVEg043ihVUA=s64",
      "userId": "03611350071843918342"
     },
     "user_tz": -60
    },
    "id": "GXVMmI5j2DEX",
    "outputId": "1dc8fd1c-b5b3-4143-850a-79f2611a7f45",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5600, 6000, 1) (5600, 7) (1400, 6000, 1) (1400, 7)\n",
      "[[-1.6363914 ]\n",
      " [ 0.50326234]\n",
      " [ 1.114592  ]]\n",
      "[0 1 0 0 0 0 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nwith seed(1024), trainXs[101, 7:10]:\\n[[-16.613968]\\n [-15.085644]\\n [-15.085644]]\\n [0 0 0 0 0 1 0]\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(trainXs.shape, trainYs.shape, testXs.shape, testYs.shape)\n",
    "print(trainXs[101, 7:10])\n",
    "print(trainYs[101,:])\n",
    "\n",
    "if useCNN == '1D':\n",
    "    plt.plot(trainXs[5010,:])\n",
    "if useCNN == '2D':\n",
    "    plt.plot(trainXs[5010,:].flatten().reshape(trainXs.shape[1], conv2Dcols*conv2Drows))\n",
    "'''\n",
    "with seed(1024), trainXs[101, 7:10]:\n",
    "[[-16.613968]\n",
    " [-15.085644]\n",
    " [-15.085644]]\n",
    " [0 0 0 0 0 1 0]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 593
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 21890,
     "status": "ok",
     "timestamp": 1592661105135,
     "user": {
      "displayName": "Helder Daniel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9_X9PHXyfxsFqdQBJarSFy5TpLITVEg043ihVUA=s64",
      "userId": "03611350071843918342"
     },
     "user_tz": -60
    },
    "id": "xjhjrKrigbcc",
    "outputId": "79eb6d6f-c85d-4362-94f2-d5b6861f2606"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up ANN model ...\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 6000, 32)          672       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 1200, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 1200, 64)          41024     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 240, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 240, 128)          163968    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 48, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 48, 64)            163904    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 10, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 10, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 640)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 7)                 4487      \n",
      "=================================================================\n",
      "Total params: 374,055\n",
      "Trainable params: 374,055\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def prepareInput(X, y, batchSize=256, shuffle=False):\n",
    "    seed = 0\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((X, y))\n",
    "    # Shuffle, repeat, and batch the examples.\n",
    "    dataset = dataset.cache()\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(X.shape[0], seed, reshuffle_each_iteration=True)\n",
    "    dataset = dataset.repeat() #repeat same dataset next epoch\n",
    "    dataset = dataset.batch(batchSize, drop_remainder=True) #drops remaining samples < batchSize\n",
    "    # Return the dataset.\n",
    "    return dataset\n",
    "\n",
    "def setUpModel(inputLen):  \n",
    "    #Load or setup model\n",
    "    if loadModel:\n",
    "        print('Loading ANN model ...')\n",
    "        model = tf.keras.models.load_model(loadModelFN)\n",
    "        #force change optimizer and metrics\n",
    "        if forceCompileModel:\n",
    "            model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "    else:\n",
    "        print(\"Setting up ANN model ...\")\n",
    "        if useCNN == '1D':\n",
    "            model = setupModel(inputLen, numClasses, windowSlice, conv2Dcols, dropOutRatio, filters)\n",
    "        if useCNN == '2D':\n",
    "            model = setupCNN2D(inputLen, numClasses, windowSlice, conv2Drows, conv2Dcols, dropOutRatio, filters)\n",
    "        model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "    #can also save and load TPU model\n",
    "    if useTPU:\n",
    "        print('Setting up TPU ANN model ...')\n",
    "        if tfVersion114:\n",
    "            model = setupTPUModel114(inputLen, numClasses, windowSlice, conv2Dcols, dropOutRatio, filters)\n",
    "            model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "        else:\n",
    "          model = setupTPUModel(model)\n",
    "\n",
    "        \"\"\"\n",
    "        try:\n",
    "            deviceName = os.environ['COLAB_TPU_ADDR']\n",
    "            TPUaddr = 'grpc://' + deviceName\n",
    "            print('Found TPU at: {}'.format(TPUaddr))\n",
    "        except KeyError:\n",
    "            print('TPU not found')\n",
    "            sys.exit(0)\n",
    "\n",
    "        if tfVersion114:\n",
    "            resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=TPUaddr)\n",
    "            tf.config.experimental_connect_to_host(resolver.master())\n",
    "            tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "            strategy = tf.distribute.experimental.TPUStrategy(resolver)\n",
    "            with strategy.scope():\n",
    "                model = setupModel(inputLen, numClasses, windowSlice, conv2Dcols, dropOutRatio, filters)\n",
    "        else:\n",
    "            model = tf.contrib.tpu.keras_to_tpu_model(\n",
    "                model,\n",
    "                strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
    "                tf.contrib.cluster_resolver.TPUClusterResolver(\n",
    "                tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
    "                ))\n",
    "        \"\"\"    \n",
    "\n",
    "    return model\n",
    "\n",
    "  \n",
    "def setupCallbacks():\n",
    "    #Callbacks setup\n",
    "    callbacks = []\n",
    "    if saveModel:\n",
    "        ModelCheckpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "            #default: monitor='val_acc',\n",
    "            filepath=saveBestModelFN, verbose=1, period=saveEpochs, save_best_only=True)\n",
    "        callbacks.append(ModelCheckpoint)\n",
    "    #EarlyStopStall\n",
    "    if earlyStopStall:\n",
    "        eStopStall = tf.keras.callbacks.EarlyStopping(\n",
    "            monitor=metricES, min_delta=minDeltaStop, patience=esPatienceEpochs, verbose=1)\n",
    "        callbacks.append(eStopStall)    \n",
    "    #EarlyStopACC\n",
    "    if earlyStopACC:\n",
    "        '''DOES NOT WORK'''\n",
    "        '''\n",
    "        eStopACC = tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_acc', baseline=earlyStopACCmin, patience=0)\n",
    "        callbacks.append(eStopACC)\n",
    "        '''\n",
    "        class TerminateOnACC(tf.keras.callbacks.Callback):\n",
    "            def on_epoch_end(self, epoch, logs={None}):\n",
    "                valacc = logs.get('val_acc')\n",
    "                if valacc >= earlyStopACCmin:\n",
    "                    print('\\nEpoch {}: Reached baseline val_acc {} ({})'.format(epoch+1, earlyStopACCmin, valacc))\n",
    "                    self.model.stop_training = True\n",
    "        tacc = TerminateOnACC()\n",
    "        callbacks.append(tacc)\n",
    "    #learning factor reduce   \n",
    "    if adaptLearningRate:\n",
    "        reduceLR = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor=metricLR, factor=reduceLRFactor, min_lr=minLR,  min_delta=minDeltaLR, cooldown=waitMonitorEpochs, patience=alrPatienceEpochs)\n",
    "        callbacks.append(reduceLR)\n",
    "        #print learning rate callback\n",
    "        class LearningRateMonitor(tf.keras.callbacks.Callback):\n",
    "            def on_epoch_begin(self, epoch, logs=None):\n",
    "                print(\"learning rate: \", tf.keras.backend.eval(self.model.optimizer.lr))\n",
    "        lrm = LearningRateMonitor()\n",
    "        callbacks.append(lrm)\n",
    "    #Increase and decrease learning rate                                    \n",
    "    if bouncingLearningRate:\n",
    "        class bounceLearningRate(tf.keras.callbacks.Callback):\n",
    "            def __init__(self, epochs=40, dFact=0.5, up=0.0005, dn=0.00025):\n",
    "                self.lrpat   = epochs\n",
    "                self.lrdecayFactor = dFact\n",
    "                self.lrdecay = self.lrdecayFactor\n",
    "                self.upLimit = up\n",
    "                self.dnLimit = dn\n",
    "            def on_epoch_begin(self, epoch, logs=None):\n",
    "              if epoch >= self.lrpat:\n",
    "                if epoch % self.lrpat == 0:\n",
    "                    lr = tf.keras.backend.eval(self.model.optimizer.lr)\n",
    "                    if lr >=  self.upLimit: self.lrdecay = self.lrdecayFactor\n",
    "                    if lr <=  self.dnLimit: self.lrdecay = 1 / self.lrdecayFactor\n",
    "                    tf.keras.backend.set_value(model.optimizer.lr, lr*self.lrdecay)\n",
    "                    print(\"Epoch: \", epoch+1, \" learning rate: \", tf.keras.backend.eval(self.model.optimizer.lr))\n",
    "        blr = bounceLearningRate()\n",
    "        callbacks.append(blr)\n",
    "    #decaying learning rate                                    \n",
    "    if decayLearningRate:\n",
    "        class decayingLearningRate(tf.keras.callbacks.Callback):\n",
    "            lrates = [0.001, 0.0001, 0.00001, 0.000001]\n",
    "            lridx  = 0\n",
    "            lrpat  = 50 #epochs\n",
    "            def on_epoch_begin(self, epoch, logs=None):\n",
    "                if epoch % self.lrpat == 0:\n",
    "                    tf.keras.backend.set_value(model.optimizer.lr, self.lrates[self.lridx])\n",
    "                    print(\"Epoch: \", epoch+1, \" learning rate: \", tf.keras.backend.eval(self.model.optimizer.lr))\n",
    "                    self.lridx += 1\n",
    "                    if self.lridx >= len(self.lrates): self.lridx = 0 \n",
    "        dlr = decayingLearningRate()\n",
    "        callbacks.append(dlr)  \n",
    "        \n",
    "    return callbacks        \n",
    "\n",
    "#setup model\n",
    "model     = setUpModel(inputLen)\n",
    "callbacks = setupCallbacks()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 21884,
     "status": "ok",
     "timestamp": 1592661105136,
     "user": {
      "displayName": "Helder Daniel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9_X9PHXyfxsFqdQBJarSFy5TpLITVEg043ihVUA=s64",
      "userId": "03611350071843918342"
     },
     "user_tz": -60
    },
    "id": "MNo-Oci-gbcY"
   },
   "outputs": [],
   "source": [
    "if useTPU:\n",
    "    #just for TF114 (?)\n",
    "    #trainYs = trainYs.astype(np.int32)\n",
    "    #testYs  = testYs.astype(np.int32)\n",
    "    \n",
    "    #deprecated\n",
    "    '''\n",
    "    if tfVersion114:\n",
    "        pass\n",
    "    else:\n",
    "        validationSplit = 0.3;\n",
    "        splitPoint = int(trainXs.shape[0]*(1-validationSplit))\n",
    "        valXs=trainXs[splitPoint:]\n",
    "        valYs=trainYs[splitPoint:]\n",
    "        trainXs=trainXs[:splitPoint]\n",
    "        trainYs=trainYs[:splitPoint]\n",
    "    '''\n",
    "\n",
    "    print(trainXs.shape, trainYs.shape, testXs.shape, testYs.shape)\n",
    "    \n",
    "    #make dataset a multiple of batchsize\n",
    "    if tfVersion114:\n",
    "        samplesTrainXs  = int(trainXs.shape[0] / batchSize) * batchSize\n",
    "        samplesTrainYs  = int(trainYs.shape[0] / batchSize) * batchSize\n",
    "        samplesTestXs   = int(testXs.shape[0]  / batchSize) * batchSize\n",
    "        samplesTestYs   = int(testYs.shape[0]  / batchSize) * batchSize\n",
    "       \n",
    "        trainXs = trainXs[:samplesTrainXs]\n",
    "        trainYs = trainYs[:samplesTrainYs]\n",
    "        testXs  = testXs [:samplesTestXs]\n",
    "        testYs  = testYs [:samplesTestYs]\n",
    "\n",
    "    print(trainXs.shape, trainYs.shape, testXs.shape, testYs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 21877,
     "status": "ok",
     "timestamp": 1592661105137,
     "user": {
      "displayName": "Helder Daniel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9_X9PHXyfxsFqdQBJarSFy5TpLITVEg043ihVUA=s64",
      "userId": "03611350071843918342"
     },
     "user_tz": -60
    },
    "id": "cqvPM3d3kiAy"
   },
   "outputs": [],
   "source": [
    "def plotStatsClass(xlen, history, earlyStopACCmin):\n",
    "    trainEpochs = [x[0] for x in history]\n",
    "    trainAccs   = [x[1] for x in history]\n",
    "    trainLosses = [x[2] for x in history]\n",
    "    print(trainEpochs)\n",
    "    print(trainAccs)\n",
    "    print(trainLosses)\n",
    "\n",
    "    plotStats(xlen, trainEpochs, trainAccs, trainLosses, earlyStopACCmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 21872,
     "status": "ok",
     "timestamp": 1592661105138,
     "user": {
      "displayName": "Helder Daniel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9_X9PHXyfxsFqdQBJarSFy5TpLITVEg043ihVUA=s64",
      "userId": "03611350071843918342"
     },
     "user_tz": -60
    },
    "id": "7n6uWFxMe65y"
   },
   "outputs": [],
   "source": [
    "#Note: Even with loading weights and restarting program with same seed\n",
    "#training values are different\n",
    "import pickle\n",
    "\n",
    "weigthsFN = storagepath + 'weigths.pickle'\n",
    "storeWeights = False\n",
    "loadWeights  = False\n",
    "\n",
    "if storeWeights:\n",
    "    weightsFixed = model.get_weights()\n",
    "    with open(weigthsFN, 'wb') as fp:\n",
    "        pickle.dump(weightsFixed, fp)\n",
    "\n",
    "if loadWeights:\n",
    "    with open(weigthsFN, 'rb') as fp:\n",
    "        weightsFixed = pickle.load(fp)\n",
    "#print(weightsFixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 21867,
     "status": "ok",
     "timestamp": 1592661105139,
     "user": {
      "displayName": "Helder Daniel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9_X9PHXyfxsFqdQBJarSFy5TpLITVEg043ihVUA=s64",
      "userId": "03611350071843918342"
     },
     "user_tz": -60
    },
    "id": "3kfVuY-6ytQC"
   },
   "outputs": [],
   "source": [
    "#Assumes each channel have same number of points\n",
    "def reducePoints(trainXs, testXs, channels, desiredPoints):\n",
    "    samplesT  = trainXs.shape[0]\n",
    "    samplest  = testXs.shape[0]\n",
    "    points    = trainXs.shape[1]\n",
    "    npoints   = int(points/channels)\n",
    "    nSamplesT = samplesT * channels\n",
    "    nSamplest = samplest * channels\n",
    "    \n",
    "    #print(nSamplesT, nSamplest, npoints, points)\n",
    "    trainXs0 = trainXs.reshape(nSamplesT, npoints)\n",
    "    testXs0  = testXs.reshape (nSamplest, npoints)\n",
    "    trainXs0 = trainXs0[: , 0:desiredPoints]    #reduce points \n",
    "    testXs0  = testXs0 [: , 0:desiredPoints]    #reduce points \n",
    "    trainXs0 = trainXs0.reshape(samplesT, desiredPoints*channels, 1) #Add 3rd dim for Conv1D\n",
    "    testXs0  = testXs0.reshape (samplest, desiredPoints*channels, 1) #Add 3rd dim for Conv1D\n",
    "                  \n",
    "    return trainXs0, testXs0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 21860,
     "status": "ok",
     "timestamp": 1592661105139,
     "user": {
      "displayName": "Helder Daniel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9_X9PHXyfxsFqdQBJarSFy5TpLITVEg043ihVUA=s64",
      "userId": "03611350071843918342"
     },
     "user_tz": -60
    },
    "id": "XWDGtV2IlIFI"
   },
   "outputs": [],
   "source": [
    "#Assumes each class have same number of samples\n",
    "def reduceSamples(trainXs, trainYs, numClasses, desiredSamples):\n",
    "    samples = trainXs.shape[0]\n",
    "    classSamples = int(samples/numClasses)\n",
    "    #print(samples,classSamples, desiredSamples)\n",
    "    #print()\n",
    "    samplesToDelete = []\n",
    "    for i in range(numClasses):\n",
    "        start  = i * classSamples + desiredSamples\n",
    "        end    = start + classSamples - desiredSamples\n",
    "        #print(start, end)\n",
    "        delete = list(range(start,end))\n",
    "        samplesToDelete.extend(delete)\n",
    "\n",
    "    trainXs0 = np.delete(trainXs, samplesToDelete, 0)  #reduce samples\n",
    "    trainYs0 = np.delete(trainYs, samplesToDelete, 0)  #reduce samples\n",
    "                  \n",
    "    return trainXs0, trainYs0\n",
    "\n",
    "#print(trainXs.shape, trainYs.shape, testXs.shape, testYs.shape) \n",
    "#trainXs0, trainYs0 = reduceSamples(trainXs, trainYs, numClasses, 200)\n",
    "#print(trainXs0.shape, trainYs0.shape, testXs.shape, testYs.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 21853,
     "status": "ok",
     "timestamp": 1592661105140,
     "user": {
      "displayName": "Helder Daniel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9_X9PHXyfxsFqdQBJarSFy5TpLITVEg043ihVUA=s64",
      "userId": "03611350071843918342"
     },
     "user_tz": -60
    },
    "id": "XxxpBIfsY1VF"
   },
   "outputs": [],
   "source": [
    "#Assumes each channel have same number of points\n",
    "def reduceChannels(trainXs, testXs, numChannels, desiredChannels):\n",
    "    pointsByChannel = int(trainXs.shape[1]/numChannels)\n",
    "\n",
    "    samplesToDelete = []\n",
    "    trainXs0 = None\n",
    "    trainYs0 = None\n",
    "\n",
    "    #Convert to int\n",
    "    desiredChannels=[int(i) for i in desiredChannels]\n",
    "\n",
    "    for i in desiredChannels:\n",
    "\n",
    "        start  = i * pointsByChannel\n",
    "        end    = start + pointsByChannel\n",
    "        #print(start, end)\n",
    "\n",
    "        if trainXs0 is None:\n",
    "            trainXs0 = trainXs[:, start:end]\n",
    "            testXs0  = testXs[:, start:end]\n",
    "        else:\n",
    "            trainXs0 = np.concatenate((trainXs0, trainXs[:, start:end]), axis = 1)\n",
    "            testXs0  = np.concatenate((testXs0,  testXs[:, start:end]),  axis = 1)\n",
    "        #print(trainXs0.shape, testXs0.shape) \n",
    "                  \n",
    "    return trainXs0, testXs0\n",
    "\n",
    "#initData(data)\n",
    "#print(trainXs.shape, trainYs.shape, testXs.shape, testYs.shape) \n",
    "#trainXs0, testXs0 = reduceChannels(trainXs, testXs, 3, '2')\n",
    "#print(trainXs0.shape, trainYs.shape, testXs0.shape, testYs.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 21845,
     "status": "ok",
     "timestamp": 1592661105141,
     "user": {
      "displayName": "Helder Daniel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9_X9PHXyfxsFqdQBJarSFy5TpLITVEg043ihVUA=s64",
      "userId": "03611350071843918342"
     },
     "user_tz": -60
    },
    "id": "H4WsZGXGy4Ae",
    "outputId": "c9627cbb-cb16-42d5-af5a-f19248028ee6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#Datasets equal, all gives TRUE\\n\\nchannels = 3\\nexp = 2000\\ntrainXs0, testXs0 = reducePoints(trainXs, testXs, channels, exp)\\ntrainYs0 = trainYs\\ntestYs0  = testYs\\n        \\nnumClasses = 7\\nexp = 800  #use eg.: 600 to give different datasets\\ntrainXs1, trainYs1 = reduceSamples(trainXs, trainYs, numClasses, exp)\\ntestXs1 = testXs\\ntestYs1 = testYs\\n\\nprint(np.array_equal(trainXs,trainXs0)) # test if same shape, same elements values\\nprint(np.array_equal(trainYs,trainYs0)) # test if same shape, same elements values\\nprint(np.array_equal(testXs, testXs0))  # test if same shape, same elements values\\nprint(np.array_equal(testYs, testYs0))  # test if same shape, same elements values\\n\\nprint(np.array_equal(trainXs,trainXs1)) # test if same shape, same elements values\\nprint(np.array_equal(trainYs,trainYs1)) # test if same shape, same elements values\\nprint(np.array_equal(testXs, testXs1))  # test if same shape, same elements values\\nprint(np.array_equal(testYs, testYs1))  # test if same shape, same elements values\\n\\n#Not needed if above used\\nprint(np.array_equal(trainXs0,trainXs1)) # test if same shape, same elements values\\nprint(np.array_equal(trainYs0,trainYs1)) # test if same shape, same elements values\\nprint(np.array_equal(testXs0, testXs1))  # test if same shape, same elements values\\nprint(np.array_equal(testYs0, testYs1))  # test if same shape, same elements values\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#Datasets equal, all gives TRUE\n",
    "\n",
    "channels = 3\n",
    "exp = 2000\n",
    "trainXs0, testXs0 = reducePoints(trainXs, testXs, channels, exp)\n",
    "trainYs0 = trainYs\n",
    "testYs0  = testYs\n",
    "        \n",
    "numClasses = 7\n",
    "exp = 800  #use eg.: 600 to give different datasets\n",
    "trainXs1, trainYs1 = reduceSamples(trainXs, trainYs, numClasses, exp)\n",
    "testXs1 = testXs\n",
    "testYs1 = testYs\n",
    "\n",
    "print(np.array_equal(trainXs,trainXs0)) # test if same shape, same elements values\n",
    "print(np.array_equal(trainYs,trainYs0)) # test if same shape, same elements values\n",
    "print(np.array_equal(testXs, testXs0))  # test if same shape, same elements values\n",
    "print(np.array_equal(testYs, testYs0))  # test if same shape, same elements values\n",
    "\n",
    "print(np.array_equal(trainXs,trainXs1)) # test if same shape, same elements values\n",
    "print(np.array_equal(trainYs,trainYs1)) # test if same shape, same elements values\n",
    "print(np.array_equal(testXs, testXs1))  # test if same shape, same elements values\n",
    "print(np.array_equal(testYs, testYs1))  # test if same shape, same elements values\n",
    "\n",
    "#Not needed if above used\n",
    "print(np.array_equal(trainXs0,trainXs1)) # test if same shape, same elements values\n",
    "print(np.array_equal(trainYs0,trainYs1)) # test if same shape, same elements values\n",
    "print(np.array_equal(testXs0, testXs1))  # test if same shape, same elements values\n",
    "print(np.array_equal(testYs0, testYs1))  # test if same shape, same elements values\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 43976,
     "status": "error",
     "timestamp": 1592661127280,
     "user": {
      "displayName": "Helder Daniel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9_X9PHXyfxsFqdQBJarSFy5TpLITVEg043ihVUA=s64",
      "userId": "03611350071843918342"
     },
     "user_tz": -60
    },
    "id": "GTMnlwUZFnpb",
    "outputId": "a0874350-2420-486b-9b13-33adcd2cf664"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jun 20 13:51:46 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   41C    P0    24W /  75W |    211MiB /  7611MiB |      0%      Default |\n",
      "|                               |                      |                 ERR! |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n",
      "Experiment '0', run 6\n",
      "Preparing data ...\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "done\n",
      "Setting up data ...\n",
      "done\n",
      "[[-4.387375]\n",
      " [-4.08171 ]\n",
      " [-3.776045]]\n",
      "(5600, 100, 1) (5600, 7) (1400, 100, 1) (1400, 7)\n",
      "Setting up ANN model ...\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Trainning run: 6\n",
      "0.0005\n",
      "32\n",
      "Epoch 1/200\n",
      "175/175 [==============================] - ETA: 0s - loss: 0.1188 - acc: 0.2127 - mae: 0.2383 - mse: 0.1188\n",
      "Epoch 00001: val_loss improved from inf to 0.11035, saving model to gdrive/My Drive/Colab Notebooks/00data/record/modelBest.h5\n",
      "175/175 [==============================] - 2s 10ms/step - loss: 0.1188 - acc: 0.2127 - mae: 0.2383 - mse: 0.1188 - val_loss: 0.1104 - val_acc: 0.3114 - val_mae: 0.2280 - val_mse: 0.1104\n",
      "Epoch 2/200\n",
      "171/175 [============================>.] - ETA: 0s - loss: 0.1055 - acc: 0.3629 - mae: 0.2138 - mse: 0.1055\n",
      "Epoch 00002: val_loss improved from 0.11035 to 0.09623, saving model to gdrive/My Drive/Colab Notebooks/00data/record/modelBest.h5\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1055 - acc: 0.3636 - mae: 0.2138 - mse: 0.1055 - val_loss: 0.0962 - val_acc: 0.4350 - val_mae: 0.2035 - val_mse: 0.0962\n",
      "Epoch 3/200\n",
      "173/175 [============================>.] - ETA: 0s - loss: 0.0945 - acc: 0.4581 - mae: 0.1930 - mse: 0.0945\n",
      "Epoch 00003: val_loss improved from 0.09623 to 0.08860, saving model to gdrive/My Drive/Colab Notebooks/00data/record/modelBest.h5\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0947 - acc: 0.4561 - mae: 0.1932 - mse: 0.0947 - val_loss: 0.0886 - val_acc: 0.5150 - val_mae: 0.1756 - val_mse: 0.0886\n",
      "Epoch 4/200\n",
      "173/175 [============================>.] - ETA: 0s - loss: 0.0840 - acc: 0.5275 - mae: 0.1725 - mse: 0.0840\n",
      "Epoch 00004: val_loss improved from 0.08860 to 0.08084, saving model to gdrive/My Drive/Colab Notebooks/00data/record/modelBest.h5\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0841 - acc: 0.5270 - mae: 0.1726 - mse: 0.0841 - val_loss: 0.0808 - val_acc: 0.5557 - val_mae: 0.1696 - val_mse: 0.0808\n",
      "Epoch 5/200\n",
      "173/175 [============================>.] - ETA: 0s - loss: 0.0737 - acc: 0.5956 - mae: 0.1519 - mse: 0.0737\n",
      "Epoch 00005: val_loss improved from 0.08084 to 0.07786, saving model to gdrive/My Drive/Colab Notebooks/00data/record/modelBest.h5\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0737 - acc: 0.5955 - mae: 0.1517 - mse: 0.0737 - val_loss: 0.0779 - val_acc: 0.5793 - val_mae: 0.1460 - val_mse: 0.0779\n",
      "Epoch 6/200\n",
      "164/175 [===========================>..] - ETA: 0s - loss: 0.0680 - acc: 0.6277 - mae: 0.1404 - mse: 0.0680\n",
      "Epoch 00006: val_loss improved from 0.07786 to 0.06312, saving model to gdrive/My Drive/Colab Notebooks/00data/record/modelBest.h5\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0680 - acc: 0.6273 - mae: 0.1402 - mse: 0.0680 - val_loss: 0.0631 - val_acc: 0.6450 - val_mae: 0.1301 - val_mse: 0.0631\n",
      "Epoch 7/200\n",
      "168/175 [===========================>..] - ETA: 0s - loss: 0.0640 - acc: 0.6510 - mae: 0.1325 - mse: 0.0640\n",
      "Epoch 00007: val_loss improved from 0.06312 to 0.06100, saving model to gdrive/My Drive/Colab Notebooks/00data/record/modelBest.h5\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0640 - acc: 0.6505 - mae: 0.1324 - mse: 0.0640 - val_loss: 0.0610 - val_acc: 0.6536 - val_mae: 0.1213 - val_mse: 0.0610\n",
      "Epoch 8/200\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.0626 - acc: 0.6595 - mae: 0.1273 - mse: 0.0626\n",
      "Epoch 00008: val_loss did not improve from 0.06100\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.0627 - acc: 0.6589 - mae: 0.1274 - mse: 0.0627 - val_loss: 0.0714 - val_acc: 0.5864 - val_mae: 0.1391 - val_mse: 0.0714\n",
      "Epoch 9/200\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.0596 - acc: 0.6762 - mae: 0.1222 - mse: 0.0596\n",
      "Epoch 00009: val_loss improved from 0.06100 to 0.05693, saving model to gdrive/My Drive/Colab Notebooks/00data/record/modelBest.h5\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0595 - acc: 0.6762 - mae: 0.1222 - mse: 0.0595 - val_loss: 0.0569 - val_acc: 0.6943 - val_mae: 0.1132 - val_mse: 0.0569\n",
      "Epoch 10/200\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.0545 - acc: 0.7103 - mae: 0.1124 - mse: 0.0545\n",
      "Epoch 00010: val_loss did not improve from 0.05693\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.0544 - acc: 0.7105 - mae: 0.1124 - mse: 0.0544 - val_loss: 0.0591 - val_acc: 0.6907 - val_mae: 0.1109 - val_mse: 0.0591\n",
      "Epoch 11/200\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.0522 - acc: 0.7284 - mae: 0.1069 - mse: 0.0522\n",
      "Epoch 00011: val_loss did not improve from 0.05693\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.0522 - acc: 0.7284 - mae: 0.1069 - mse: 0.0522 - val_loss: 0.0622 - val_acc: 0.6679 - val_mae: 0.1151 - val_mse: 0.0622\n",
      "Epoch 12/200\n",
      "172/175 [============================>.] - ETA: 0s - loss: 0.0514 - acc: 0.7384 - mae: 0.1058 - mse: 0.0514\n",
      "Epoch 00012: val_loss improved from 0.05693 to 0.05264, saving model to gdrive/My Drive/Colab Notebooks/00data/record/modelBest.h5\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0514 - acc: 0.7387 - mae: 0.1058 - mse: 0.0514 - val_loss: 0.0526 - val_acc: 0.7314 - val_mae: 0.1026 - val_mse: 0.0526\n",
      "Epoch 13/200\n",
      "  1/175 [..............................] - ETA: 0s - loss: 0.0587 - acc: 0.6875 - mae: 0.1135 - mse: 0.0587"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-a69d9a466462>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    220\u001b[0m                     \u001b[0;31m#validation_steps=int(testXs.shape[0]/batchSize), #required if steps_per_epoch used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                     \u001b[0;31m#validation_freq=5,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m                     \u001b[0;31m#verbose=1,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                 )\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Fit with TF1.14 losts session if data is to big.\n",
    "#it works with undersample=10\n",
    "\n",
    "#TF1.13.1 has no problem :)\n",
    "\n",
    "import psutil\n",
    "\n",
    "!nvidia-smi\n",
    "    \n",
    "epochs    = 200\n",
    "batchSize = 32\n",
    "initialLR = 0.0005\n",
    "amsGrad   = False\n",
    "\n",
    "bouncingLearningRate = True\n",
    "earlyStopACC         = True\n",
    "earlyStopStall       = True\n",
    "earlyStopACCmin      = 1.0 #0.975 #0.995\n",
    "esPatienceEpochs     = 30\n",
    "channels             = 3\n",
    "\n",
    "resumeLog         = True    #resumes interrupted Log. If false restarts logging experiments\n",
    "                            #HOWEVER if log file exists, adds to logfile (DOES NOT clear it)\n",
    "testSamples       = False   #Samples is 1 (S)\n",
    "testPoints        = False   #Points  is 2 (P)\n",
    "testChannels      = True\n",
    "shuffleEveryRun   = True    #Shuffle is B, no shuffle is A\n",
    "shuffleEveryEpoch = True\n",
    "resetModel        = True\n",
    "\n",
    "logFNL = exppath + 'experiment.log'\n",
    "runs   = 30 #25\n",
    "\n",
    "if testPoints: #for Points\n",
    "    init  =  2000\n",
    "    step  = -200\n",
    "    last  =  1990\n",
    "    extra = [150, 100, 50, 25]\n",
    "\n",
    "if testSamples: #for Samples\n",
    "    init  =  800\n",
    "    step  = -100   \n",
    "    last  =   99\n",
    "    extra = [50, 25]\n",
    "\n",
    "if testChannels: #strings is easiaer to use as key in dict\n",
    "    experiments = ['0', '1', '2']#['12', '02', '01', '0', '1', '2']\n",
    "else:\n",
    "    experiments = list(range(init, last, step)) + extra #just for above    \n",
    "\n",
    "initRun = 0\n",
    "\n",
    "#Adds to existing log, if log exists\n",
    "import os.path\n",
    "if os.path.isfile(logFNL):\n",
    "\n",
    "    #initExp = init\n",
    "    if resumeLog:    #Resumes interruped log\n",
    "        log = SimpleLog.load(logFNL)\n",
    "        lastEntrie = log.getLast()\n",
    "        lastExp    = lastEntrie[1][0]\n",
    "        lastRun    = lastEntrie[1][1]\n",
    "        if lastRun >= runs-1:\n",
    "            initRun = 0\n",
    "            idx = experiments.index(lastExp)\n",
    "            initExp = experiments[idx+1]\n",
    "        else:\n",
    "            initExp = lastExp\n",
    "            initRun = lastRun + 1\n",
    "    \n",
    "    idx = experiments.index(initExp)\n",
    "    experiments = experiments[idx:]\n",
    "    \n",
    "#This way always append if log already exist, HOWEVER only resumes log if resumeLog == True\n",
    "else:\n",
    "    log = SimpleLog()\n",
    "\n",
    "\n",
    "initialized = False\n",
    "for exp in experiments:\n",
    "    history = [] \n",
    "    executedRuns = 0\n",
    "    if initialized: initRun = 0\n",
    "    \n",
    "    if testPoints:\n",
    "        model = setUpModel(exp*channels)\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(lr=initialLR, amsgrad=amsGrad), loss='mse', metrics=['acc', 'mae', 'mse'])\n",
    "        #model.compile(optimizer=tf.keras.optimizers.SGD(lr=initialLR), loss='mse', metrics=['acc', 'mae', 'mse'])    \n",
    "    \n",
    "    for run in range(initRun, runs):\n",
    "        initialized = True\n",
    "        print(\"Experiment '{}', run {}\".format(exp, run))\n",
    "        #continue\n",
    "\n",
    "\n",
    "        #reshuffle train and test sets each run\n",
    "        if shuffleEveryRun:\n",
    "            trainXs, trainYs, testXs, testYs = initData(data)\n",
    "            \n",
    "        #Check if shuffled\n",
    "        '''\n",
    "        with seed(1024), trainXs[51, 7:10]:\n",
    "        [[27.401766]\n",
    "         [27.096102]\n",
    "         [27.096102]]\n",
    "        '''\n",
    "        print(trainXs[51, 7:10])\n",
    "\n",
    "        if testPoints:\n",
    "            trainXs0, testXs0 = reducePoints(trainXs, testXs, channels, exp)\n",
    "            trainYs0 = trainYs\n",
    "            testYs0  = testYs\n",
    "        \n",
    "        if testSamples:\n",
    "            trainXs0, trainYs0 = reduceSamples(trainXs, trainYs, numClasses, exp)\n",
    "            testXs0 = testXs\n",
    "            testYs0 = testYs\n",
    "\n",
    "        if testChannels:\n",
    "            trainXs0, testXs0 = reduceChannels(trainXs, testXs, channels, exp)\n",
    "            trainYs0 = trainYs\n",
    "            testYs0  = testYs          \n",
    "\n",
    "        trainXs0, testXs0 = reducePoints(trainXs0, testXs0, len(exp), 100)\n",
    "        #trainXs0, trainYs0 = reduceSamples(trainXs0, trainYs0, numClasses, 100)\n",
    "        print(trainXs0.shape, trainYs0.shape, testXs0.shape, testYs0.shape)            \n",
    "\n",
    "\n",
    "        if resetModel:\n",
    "            #Reshape input layer by recreating model\n",
    "            #does not reset model metrics, must restart callbacks\n",
    "            #if testPoints: inlen = exp*channels\n",
    "            #else:          inlen = inputLen\n",
    "            #model = setUpModel(inlen)\n",
    "            model = setUpModel(trainXs0.shape[1])\n",
    "\n",
    "            #Reset model without recreating it by shuffling weights (faster)\n",
    "            #does not reset model metrics, must restart callbacks\n",
    "            #HOWEVER just shuffling weigts is not a good approach, cause after some runs stalls\n",
    "            '''           \n",
    "            weights = model.get_weights()\n",
    "            weights = [np.random.permutation(w.flat).reshape(w.shape) for w in weights]\n",
    "            # Faster, but less random: only permutes along the first dimension\n",
    "            # weights = [np.random.permutation(w) for w in weights]\n",
    "            model.set_weights(weights)\n",
    "            '''\n",
    "\n",
    "            #Set fixed waits\n",
    "            if loadWeights:\n",
    "                print('loading fixed weights')\n",
    "                model.set_weights(weightsFixed)\n",
    "\n",
    "            model.compile(optimizer=tf.keras.optimizers.Adam(lr=initialLR, amsgrad=amsGrad), loss='mse', metrics=['acc', 'mae', 'mse'])\n",
    "            #model.compile(optimizer=tf.keras.optimizers.SGD(lr=initialLR), loss='mse', metrics=['acc', 'mae', 'mse'])    \n",
    "\n",
    "            #Reset callbacks, and callbacks status to clear metrics\n",
    "            callbacks = setupCallbacks()\n",
    "\n",
    "\n",
    "        #Train model\n",
    "        if train:\n",
    "            print(\"Trainning run:\", run)\n",
    "            start = time.time()\n",
    "\n",
    "            if True: #useTPU:\n",
    "                #trainXsB = np.array_split(trainXs, parts)#[:-1]\n",
    "                #trainYsB = np.array_split(trainYs, parts)#[:-1]\n",
    "\n",
    "                print(initialLR)\n",
    "                print(batchSize)\n",
    "                #print(len(trainXsB), len(trainYsB))\n",
    "                #print(trainXsB[0].shape, trainYsB[0].shape)\n",
    "                #print(trainXsB[len(trainXsB)-1].shape, trainYsB[len(trainXsB)-1].shape)\n",
    "\n",
    "                #trainResponse = trainModel(trainXs, trainYs, epochs, batchSize, callbacks, shuffleValData)\n",
    "                '''\n",
    "                for e in range(epochs):\n",
    "                    print(f'Epoch: {e+1:04d}/{epochs:04d}')\n",
    "                    for p in range(parts):\n",
    "                        print(f'part: {p+1:04d}/{parts:04d}')\n",
    "                        trainResponse = model.fit(\n",
    "                                    trainXsB[p], trainYsB[p],\n",
    "                                    epochs=1,\n",
    "                                    batch_size=batchSize, #or 1 or None?\n",
    "                                    #validation_split=0.3,\n",
    "                                    #validation_data = (valXs,valYs),\n",
    "                                    #callbacks=callbacks,\n",
    "                                    #verbose=1, #default\n",
    "                                    ## steps_per_epoch=1,  #Why this? 1.14+ only?\n",
    "                                    )\n",
    "\n",
    "                trainResponse = model.fit(\n",
    "                                    trainXs, trainYs,\n",
    "                                    epochs=epochs,\n",
    "                                    batch_size=batchSize,\n",
    "                                    #validation_split=0.3,\n",
    "                                    validation_data = (valXs,valYs),\n",
    "                                    callbacks=callbacks,\n",
    "                                    #verbose=1, #default\n",
    "                                    #steps_per_epoch=1,  #Why this?\n",
    "                                    )\n",
    "\n",
    "                '''\n",
    "                trainResponse = model.fit(\n",
    "                    #Must fix samples to be multiple of TPUs\n",
    "                    trainXs0, trainYs0,\n",
    "                    #Fix samples to be multiple of TPUs, shuffle, etc.\n",
    "                    #prepareInput(trainXs, trainYs, batchSize, shuffle=True),\n",
    "                    epochs=epochs,\n",
    "                    #cannot be used with dataset as input\n",
    "                    batch_size=batchSize,\n",
    "                    #steps_per_epoch=int(trainXs.shape[0]/batchSize), #Must be samples/batchSize to run all dataset\n",
    "                    shuffle=shuffleEveryEpoch,\n",
    "                    #Cannot use with TPU distribution strategies\n",
    "                    #validation_split=0.3, #use 30% of samples to validate \n",
    "                    validation_data=(testXs0, testYs0),\n",
    "                    #validation_data=(valXs,valYs),\n",
    "                    #Fix samples to be multiple of TPU\n",
    "                    #validation_data=prepareInput(valXs,valYs, valBatchSize, shuffle=False),\n",
    "                    #validation_steps=int(testXs.shape[0]/batchSize), #required if steps_per_epoch used\n",
    "                    #validation_freq=5,\n",
    "                    callbacks=callbacks,\n",
    "                    #verbose=1,\n",
    "                )\n",
    "\n",
    "\n",
    "            else:\n",
    "                !nvidia-smi\n",
    "                trainResponse = trainModel(trainXs, trainYs, epochs, batchSize, callbacks, shuffleValData)\n",
    "\n",
    "            end = time.time()\n",
    "            trainTime = end - start\n",
    "            executedRuns += 1\n",
    "            print('\\nTrain time: ', trainTime)\n",
    "            #print(response.history.keys())\n",
    "            #loss = trainResponse.history['loss'][0]\n",
    "            #acc  = trainResponse.history['acc'][0]\n",
    "            #print('Train loss:', loss, ', acc: ', acc)\n",
    "\n",
    "            #Save last model\n",
    "            '''\n",
    "            if saveModel:\n",
    "                print('Saving ANN last model: ', saveLastModelFN)\n",
    "                tf.keras.models.save_model(model, saveLastModelFN)\n",
    "            '''\n",
    "\n",
    "            numEpochs = len(trainResponse.history['val_acc'])\n",
    "            bestAcc   = max(trainResponse.history['val_acc'])\n",
    "            bestLoss  = min(trainResponse.history['val_loss'])\n",
    "            history.append((numEpochs, bestAcc, bestLoss, trainTime))\n",
    "\n",
    "            log.add((exp, run, numEpochs, bestAcc, bestLoss, trainTime))\n",
    "            #log.add((exp, run, numEpochs, bestAcc, bestLoss, trainTime, psutil.virtual_memory()))\n",
    "            #log.add((exp, run, trainResponse))\n",
    "            log.save(logFN)\n",
    "\n",
    "            if executedRuns > 1: #need at least 2 data points to compute var, mean, and stdev\n",
    "                plotStatsClass(executedRuns, history, earlyStopACCmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 43961,
     "status": "aborted",
     "timestamp": 1592661127273,
     "user": {
      "displayName": "Helder Daniel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9_X9PHXyfxsFqdQBJarSFy5TpLITVEg043ihVUA=s64",
      "userId": "03611350071843918342"
     },
     "user_tz": -60
    },
    "id": "rutMRQOs6JgA"
   },
   "outputs": [],
   "source": [
    "plotStatsClass(executedRuns, history, earlyStopACCmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 43957,
     "status": "aborted",
     "timestamp": 1592661127277,
     "user": {
      "displayName": "Helder Daniel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9_X9PHXyfxsFqdQBJarSFy5TpLITVEg043ihVUA=s64",
      "userId": "03611350071843918342"
     },
     "user_tz": -60
    },
    "id": "WVpkwrZ6MuW-"
   },
   "outputs": [],
   "source": [
    "#evaluate\n",
    "print('\\nEvaluating on last model: ', saveLastModelFN)\n",
    "#model = tf.keras.models.load_model(saveLastModelFN)\n",
    "testResponse = model.evaluate(testXs, testYs, verbose=1)\n",
    "print('Evaluation loss: ', testResponse[0], ', acc: ', testResponse[1])\n",
    "print('Evaluation mean abs error: ', testResponse[2], ', mean sqd error: ', testResponse[3])\n",
    "\n",
    "#saveBestModelFN = recordpath + 'cnnctbu/01-cnn32_1d-raw-3000-99.929.h5'\n",
    "#print('\\nEvaluating on best model: ', saveBestModelFN)\n",
    "model = tf.keras.models.load_model(saveBestModelFN)\n",
    "testResponse = model.evaluate(testXs, testYs, verbose=1)\n",
    "print('Evaluation loss: ', testResponse[0], ', acc: ', testResponse[1])\n",
    "print('Evaluation mean abs error: ', testResponse[2], ', mean sqd error: ', testResponse[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 43951,
     "status": "aborted",
     "timestamp": 1592661127278,
     "user": {
      "displayName": "Helder Daniel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9_X9PHXyfxsFqdQBJarSFy5TpLITVEg043ihVUA=s64",
      "userId": "03611350071843918342"
     },
     "user_tz": -60
    },
    "id": "-taQi9z2b4cs"
   },
   "outputs": [],
   "source": [
    "#print data measured\n",
    "print(model.metrics_names)\n",
    "print(trainResponse.history.keys())\n",
    "\n",
    "#print max acc\n",
    "maxacc = max(trainResponse.history['val_acc'][0:epochs])\n",
    "index = trainResponse.history['val_acc'][0:epochs].index(maxacc)\n",
    "minloss = trainResponse.history['val_loss'][index]\n",
    "print(index, maxacc, minloss)\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(trainResponse.history['acc'])\n",
    "plt.plot(trainResponse.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(trainResponse.history['loss'])\n",
    "plt.plot(trainResponse.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "classifier-v15.2.ipynb",
   "provenance": [
    {
     "file_id": "1SB88fA9IkYE0Rxv8IKG_ZFt2Gte9O_YU",
     "timestamp": 1564329120841
    },
    {
     "file_id": "1Tw_YvHlNK7cDjAMgMJkf0Zn8Hph9E1_U",
     "timestamp": 1564295778520
    },
    {
     "file_id": "1s9NteMqCR2JS__RHowTt66WJk2HYIqV5",
     "timestamp": 1562659536905
    },
    {
     "file_id": "1ukV34Wnghytj9oopbFhBH2GtlWxQVLXr",
     "timestamp": 1560302375163
    },
    {
     "file_id": "1SCne2jBbLssAXzBL3RyWx3OBMoIxUG3M",
     "timestamp": 1560298498064
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
